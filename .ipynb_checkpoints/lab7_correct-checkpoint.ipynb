{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 1\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-k*x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1.0-sigmoid(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1.0 - x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 10000\n",
      "epochs: 20000\n",
      "epochs: 30000\n",
      "epochs: 40000\n",
      "epochs: 50000\n",
      "epochs: 60000\n",
      "epochs: 70000\n",
      "epochs: 80000\n",
      "epochs: 90000\n",
      "[0 0] [  2.13906693e-05]\n",
      "[0 1] [ 0.99716981]\n",
      "[1 0] [ 0.99582428]\n",
      "[1 1] [ 0.00072377]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe99897eeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "array  = []\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.activation = tanh\n",
    "        self.activation_prime = tanh_prime\n",
    "\n",
    "        # Set weights\n",
    "        self.weights = []\n",
    "        # layers = [2,2,1]\n",
    "        # range of weight values (-1,1)\n",
    "        # input and hidden layers - random((2+1, 2+1)) : 3 x 3\n",
    "        \n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1\n",
    "            self.weights.append(r)\n",
    "        # output layer - random((2+1, 1)) : 3 x 1\n",
    "        r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n",
    "        self.weights.append(r)\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.2, epochs=100000):\n",
    "        # Add column of ones to X\n",
    "        # This is to add the bias unit to the input layer\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        X = np.concatenate((ones.T, X), axis=1)\n",
    "         \n",
    "        for k in range(epochs):\n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]\n",
    "\n",
    "            for l in range(len(self.weights)):\n",
    "                    dot_value = np.dot(a[l], self.weights[l])\n",
    "                    activation = self.activation(dot_value)\n",
    "                    a.append(activation)\n",
    "            # output layer\n",
    "            error = y[i] - a[-1]\n",
    "            array.append(abs(error))\n",
    "            deltas = [error * self.activation_prime(a[-1])]\n",
    "\n",
    "            # we need to begin at the second to last layer \n",
    "            # (a layer before the output layer)\n",
    "            for l in range(len(a) - 2, 0, -1): \n",
    "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
    "\n",
    "            # reverse\n",
    "            # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
    "            deltas.reverse()\n",
    "\n",
    "            # backpropagation\n",
    "            # 1. Multiply its output delta and input activation \n",
    "            #    to get the gradient of the weight.\n",
    "            # 2. Subtract a ratio (percentage) of the gradient from the weight.\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(a[i])\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                self.weights[i] += learning_rate * layer.T.dot(delta)\n",
    "\n",
    "            if k % 10000 == 0: \n",
    "                print('epochs:', k)\n",
    "        \n",
    "    def predict(self, x): \n",
    "    \n",
    "        a = np.concatenate((np.ones(1).T, np.array(x)))      \n",
    "\n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = self.activation(np.dot(a, self.weights[l]))\n",
    "        return a\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    nn = NeuralNetwork([2,2,1])\n",
    "    X = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]])\n",
    "    y = np.array([0, 1, 1, 0])\n",
    "#     X = np.array([[-1, -1],\n",
    "#                   [-1, 1],\n",
    "#                   [1, -1],\n",
    "#                   [1, 1]])\n",
    "#     y = np.array([0, 1, 1, 0])\n",
    "\n",
    "    nn.fit(X, y)\n",
    "    for e in X:\n",
    "        print(e,nn.predict(e))\n",
    "    plt.plot(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
