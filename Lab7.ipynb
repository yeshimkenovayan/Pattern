{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern recognition: Lab 7\n",
    "### Tasks:\n",
    "* Plot the error\n",
    "* Model XOR with the help of sigmoid\n",
    "* Add moments rule to learning equation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 1\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-k*x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1.0-sigmoid(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1.0 - x**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 10000\n",
      "epochs: 20000\n",
      "epochs: 30000\n",
      "epochs: 40000\n",
      "epochs: 50000\n",
      "epochs: 60000\n",
      "epochs: 70000\n",
      "epochs: 80000\n",
      "epochs: 90000\n",
      "[0 0] [-0.00014169]\n",
      "[0 1] [ 0.99706087]\n",
      "[1 0] [ 0.99627839]\n",
      "[1 1] [ 0.00271722]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAD8CAYAAABZ/vJZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x95493ba978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.activation = tanh\n",
    "        self.activation_prime = tanh_prime\n",
    "\n",
    "        # Set weights\n",
    "        self.weights = []\n",
    "        # layers = [2,2,1]\n",
    "        # range of weight values (-1,1)\n",
    "        # input and hidden layers - random((2+1, 2+1)) : 3 x 3\n",
    "        \n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1\n",
    "            self.weights.append(r)\n",
    "        # output layer - random((2+1, 1)) : 3 x 1\n",
    "        r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n",
    "        self.weights.append(r)\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.2, epochs=100000):\n",
    "        # Add column of ones to X\n",
    "        # This is to add the bias unit to the input layer\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        X = np.concatenate((ones.T, X), axis=1)\n",
    "         \n",
    "        for k in range(epochs):\n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]\n",
    "\n",
    "            for l in range(len(self.weights)):\n",
    "                    dot_value = np.dot(a[l], self.weights[l])\n",
    "                    activation = self.activation(dot_value)\n",
    "                    a.append(activation)\n",
    "            # output layer\n",
    "            error = y[i] - a[-1]\n",
    "            deltas = [error * self.activation_prime(a[-1])]\n",
    "\n",
    "            # we need to begin at the second to last layer \n",
    "            # (a layer before the output layer)\n",
    "            for l in range(len(a) - 2, 0, -1): \n",
    "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
    "\n",
    "            # reverse\n",
    "            # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
    "            deltas.reverse()\n",
    "\n",
    "            # backpropagation\n",
    "            # 1. Multiply its output delta and input activation \n",
    "            #    to get the gradient of the weight.\n",
    "            # 2. Subtract a ratio (percentage) of the gradient from the weight.\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(a[i])\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                self.weights[i] += learning_rate * layer.T.dot(delta)\n",
    "\n",
    "            if k % 10000 == 0: \n",
    "                print('epochs:', k)\n",
    "                \n",
    "        graph = plt.plot(error)\n",
    "        \n",
    "    def predict(self, x): \n",
    "    \n",
    "        a = np.concatenate((np.ones(1).T, np.array(x)))      \n",
    "\n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = self.activation(np.dot(a, self.weights[l]))\n",
    "        return a\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    nn = NeuralNetwork([2,2,1])\n",
    "    X = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]])\n",
    "    y = np.array([0, 1, 1, 0])\n",
    "#     X = np.array([[-1, -1],\n",
    "#                   [-1, 1],\n",
    "#                   [1, -1],\n",
    "#                   [1, 1]])\n",
    "#     y = np.array([0, 1, 1, 0])\n",
    "\n",
    "    nn.fit(X, y)\n",
    "    for e in X:\n",
    "        print(e,nn.predict(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
